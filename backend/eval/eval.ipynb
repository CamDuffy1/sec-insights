{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id=UUID('4d24de4e-63ee-4af5-9c97-ccae008ad887'), created_at=datetime.datetime(2024, 2, 13, 3, 56, 11, 322253), updated_at=datetime.datetime(2024, 2, 13, 3, 56, 11, 322253), url='http://llama-app-web-assets-local.s3-website.localhost.localstack.cloud:4566/sec-edgar-filings/0001326801/10-K/0001326801-23-000013/primary-document.pdf', metadata_map={<DocumentMetadataKeysEnum.SEC_DOCUMENT: 'sec_document'>: {'cik': '0001326801', 'year': 2022, 'doc_type': '10-K', 'company_name': 'Meta Platforms, Inc.', 'company_ticker': 'META', 'accession_number': '0001326801-23-000013', 'filed_as_of_date': '2023-02-02T00:00:00', 'date_as_of_change': '2023-02-01T00:00:00', 'period_of_report_date': '2022-12-31T00:00:00'}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval import get_dummy_doc\n",
    "document = get_dummy_doc()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DOCUMENT WITH SimpleDirectoryReader: META 10-K 2022\n",
      "MERGING DOCUMENT: META 10-K 2022\n"
     ]
    }
   ],
   "source": [
    "from app.chat.engine import fetch_and_read_document\n",
    "document = fetch_and_read_document(document)     # merge document pages into a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(document): 1\n",
      "type(document): <class 'list'>\n",
      "type(document[0]): <class 'llama_index.schema.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(document): {len(document)}\")\n",
    "print(f\"type(document): {type(document)}\")\n",
    "print(f\"type(document[0]): {type(document[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anyio\n",
    "from app.chat.messaging import ChatCallbackHandler\n",
    "\n",
    "send_chan, recv_chan = anyio.create_memory_object_stream(100)\n",
    "callback_handler = ChatCallbackHandler(send_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.chat.engine import get_tool_service_context\n",
    "original_service_context = get_tool_service_context(callback_handlers=[callback_handler], node_parser_type=\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 325\n",
      "\n",
      "################################################## ORIGINAL NODE ##################################################\n",
      "We have based these forward-looking statements largely on our current expectations and projections about future events and trends that we believe may affect our financial condition, results of operations, business strategy, short-term and long-term business operations and objectives, and financial needs. These forward-looking statements are subject to a number of risks, uncertainties and assumptions, including those described in Part I, Item 1A, \"Risk Factors\" in this Annual Report on Form 10-K. Moreover, we operate in a very competitive and rapidly changing environment. New risks emerge from time to time. It is not possible for our management to predict all risks, nor can we assess the impact of all factors on our business or the extent to which any factor, or combination of factors, may cause actual results to differ materially from those contained in any forward-looking statements we may make. In light of these risks, uncertainties and assumptions, the future events and trends discussed in this Annual Report on Form 10-K may not occur and actual results could differ materially and adversely from those anticipated or implied in the forward-looking statements. We undertake no obligation to revise or publicly release the results of any revision to these forward-looking statements, except as required by law. Given these risks and uncertainties, readers are cautioned not to place undue reliance on such forward-looking statements.\n"
     ]
    }
   ],
   "source": [
    "# display original node parsing\n",
    "original_node_parser = original_service_context.node_parser\n",
    "original_nodes = original_node_parser.get_nodes_from_documents(document)\n",
    "print(f\"Total nodes: {len(original_nodes)}\")\n",
    "\n",
    "from eval import format_pdf_text\n",
    "print(f\"\\n{'#'*50} ORIGINAL NODE {'#'*50}\\n{format_pdf_text(original_nodes[5].text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentence-window nodes: 2184\n",
      "\n",
      "Sentence-Window node:\n",
      "\n",
      "################################################## SENTENCE ##################################################\n",
      "Yes ☐ No ☒ Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 (Exchange Act) during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days.\n",
      "\n",
      "################################################## WINDOW ##################################################\n",
      "Employer Identification Number) 1601 Willow Road , Menlo Park , California 94025 (Address of principal executive offices and Zip Code) ( 650 ) 543-4800 (Registrant's telephone number, including area code) __________________________ Securities registered pursuant to Section 12(b) of the Act: Title of each class Trading symbol(s) Name of each exchange on which registered Class A Common Stock, $0.000006 par value META The Nasdaq Stock Market LLC Securities registered pursuant to Section 12(g) of the Act: None Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes ☒ No ☐ Indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act. Yes ☐ No ☒ Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 (Exchange Act) during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes ☒ No ☐ Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (§ 232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files).\n"
     ]
    }
   ],
   "source": [
    "sentence_window_service_context = get_tool_service_context(callback_handlers=[callback_handler], node_parser_type=\"sentence-window\")\n",
    "sentence_window_node_parser = sentence_window_service_context.node_parser\n",
    "sentence_window_nodes = sentence_window_node_parser.get_nodes_from_documents(document)\n",
    "\n",
    "print(f\"Total sentence-window nodes: {len(sentence_window_nodes)}\")\n",
    "sentence = format_pdf_text(sentence_window_nodes[5].metadata.get(\"original_text\"))\n",
    "window = format_pdf_text(sentence_window_nodes[5].metadata.get(\"window\"))\n",
    "\n",
    "print(f\"\\nSentence-Window node:\")\n",
    "print(f\"\\n{'#'*50} SENTENCE {'#'*50}\\n{sentence}\")\n",
    "print(f\"\\n{'#'*50} WINDOW {'#'*50}\\n{window}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse nodes hierarchically\n",
    "from llama_index.node_parser import get_leaf_nodes, get_root_nodes\n",
    "auto_merging_service_context = get_tool_service_context(callback_handlers=[callback_handler], node_parser_type=\"hierarchical\")\n",
    "\n",
    "hierarchical_node_parser = auto_merging_service_context.node_parser\n",
    "hierarchical_nodes = hierarchical_node_parser.get_nodes_from_documents(document)\n",
    "leaf_nodes = get_leaf_nodes(hierarchical_nodes)\n",
    "root_nodes = get_root_nodes(hierarchical_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hierarchical nodes: 2455\n",
      "Total leaf nodes: 2017\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total hierarchical nodes: {len(hierarchical_nodes)}\")\n",
    "print(f\"Total leaf nodes: {len(leaf_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice how each node is a subset of its parent:\n",
      "\n",
      "################################################## LEAF NODE ##################################################\n",
      "UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549 __________________________ FORM 10-K __________________________ (Mark One) ☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the fiscal year ended December 31 ,\n",
      "\n",
      "################################################## INTERMEDIATE NODE ##################################################\n",
      "UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549 __________________________ FORM 10-K __________________________ (Mark One) ☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the fiscal year ended December 31 , 2022 or ☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the transition period from to Commission File Number: 001-35551 __________________________ Meta Platforms, Inc. (Exact name of registrant as specified in its charter) __________________________ Delaware 20-1665019 (State or other jurisdiction of incorporation or organization) (I.R.S. Employer Identification Number) 1601 Willow Road , Menlo Park , California 94025 (Address of principal executive offices and Zip Code) ( 650 ) 543-4800 (Registrant's telephone number, including area code) __________________________ Securities registered pursuant to Section 12(b) of the Act: Title of each class Trading symbol(s) Name of each exchange on which registered Class A Common Stock, $0.000006 par value META The Nasdaq Stock Market LLC Securities registered pursuant to Section 12(g) of the Act: None Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.\n",
      "\n",
      "################################################## ROOT NODE ##################################################\n",
      "UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549 __________________________ FORM 10-K __________________________ (Mark One) ☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the fiscal year ended December 31 , 2022 or ☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the transition period from to Commission File Number: 001-35551 __________________________ Meta Platforms, Inc. (Exact name of registrant as specified in its charter) __________________________ Delaware 20-1665019 (State or other jurisdiction of incorporation or organization) (I.R.S. Employer Identification Number) 1601 Willow Road , Menlo Park , California 94025 (Address of principal executive offices and Zip Code) ( 650 ) 543-4800 (Registrant's telephone number, including area code) __________________________ Securities registered pursuant to Section 12(b) of the Act: Title of each class Trading symbol(s) Name of each exchange on which registered Class A Common Stock, $0.000006 par value META The Nasdaq Stock Market LLC Securities registered pursuant to Section 12(g) of the Act: None Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes ☒ No ☐ Indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act. Yes ☐ No ☒ Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 (Exchange Act) during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes ☒ No ☐ Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (§ 232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files). Yes ☒ No ☐ Indicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller reporting company, or an emerging growth company. See the definitions of \"large accelerated filer,\" \"accelerated filer,\" \"smaller reporting company,\" and \"emerging growth company\" in Rule 12b-2 of the Exchange Act. Large accelerated filer ☒ Accelerated filer ☐ Non-accelerated filer ☐ Smaller reporting company ☐ Emerging growth company ☐ If an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for complying with any new or revised financial accounting standards provided pursuant to Section 13(a) of the Exchange Act. ☐ Indicate by check mark whether the registrant has filed a report on and attestation to its management's assessment of the effectiveness of its internal control over financial reporting under Section 404(b) of the Sarbanes-Oxley Act (15 U.S.C. 7262(b)) by the registered public accounting firm that prepared or issued its audit report. ☒ If securities are registered pursuant to Section 12(b) of the Act, indicate by check mark whether the financial statements of the registrant included in the filing reflect the correction of an error to previously issued financial statements. ☐ Indicate by check mark whether any of those error corrections are restatements that required a recovery analysis of incentive-based compensation received by any of the registrant’s executive officers during the relevant recovery period pursuant to §240.10D-1(b). ☐ Indicate by check mark whether the registrant is a shell company (as defined in Rule 12b-2 of the Exchange Act). Yes ☐ No ☒ The aggregate market value of the voting and non-voting stock held by non-affiliates of the registrant as of June 30, 2022, the last business day of the registrant's most recently completed second fiscal quarter, was $ 378 billion based upon the closing price reported for such date on the Nasdaq Global Select Market. On January 27, 2023, the registrant had 2,225,763,078 shares of Class A common stock and 366,876,470 shares of Class B common stock outstanding. DOCUMENTS INCORPORATED BY REFERENCE Portions of the registrant's Proxy Statement for the 2023 Annual Meeting of Stockholders are incorporated herein by reference in Part III of this Annual Report on Form 10-K to the extent stated herein. Such proxy statement will be filed with the Securities and Exchange Commission within 120 days of the registrant's fiscal year ended December 31, 2022. Meta Platforms, Inc. Form 10-K TABLE OF CONTENTS Page Note About Forward-Looking Statements 3 Limitations of Key Metrics and Other Data 4 PART I Item 1. Business 7 Item 1A. Risk Factors 14 Item 1B. Unresolved Staff Comments 48 Item 2. Properties 48 Item 3. Legal Proceedings 48 Item 4. Mine Safety Disclosures 51 PART II Item 5. Market for Registrant's Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities 52 Item 6. [Reserved] 53 Item 7. Management's Discussion and Analysis of Financial Condition and Results of Operations 54 Item 7A. Quantitative and Qualitative Disclosures About Market Risk 78 Item 8. Financial Statements and Supplementary Data 80 Item 9. Changes in and Disagreements with Accountants on Accounting and Financial Disclosure 120 Item 9A. Controls and Procedures 120 Item 9B. Other Information 120 Item 9C. Disclosure Regarding Foreign Jurisdictions that Prevent Inspections 120 PART III Item 10. Directors, Executive Officers and Corporate Governance 121 Item 11. Executive Compensation 121 Item 12. Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters 121 Item 13. Certain Relationships and Related Transactions, and Director Independence 121 Item 14. Principal Account ant Fees and Services 121 PART IV Item 15. Exhibit and Financial Statement Schedules 122 Item 16.\n"
     ]
    }
   ],
   "source": [
    "# function to get parent of a hierarchical node\n",
    "get_parent_node = lambda node, all_nodes: next(i for i in all_nodes if i.id_ == node.parent_node.node_id)\n",
    "\n",
    "# get intermediate & root nodes\n",
    "leaf_node = leaf_nodes[0]\n",
    "intermediate_node = get_parent_node(leaf_node, hierarchical_nodes)\n",
    "root_node = get_parent_node(intermediate_node, hierarchical_nodes)\n",
    "\n",
    "print(f\"Notice how each node is a subset of its parent:\")\n",
    "print(f\"\\n{'#'*50} LEAF NODE {'#'*50}\\n{format_pdf_text(leaf_node.text)}\")\n",
    "print(f\"\\n{'#'*50} INTERMEDIATE NODE {'#'*50}\\n{format_pdf_text(intermediate_node.text)}\")\n",
    "print(f\"\\n{'#'*50} ROOT NODE {'#'*50}\\n{format_pdf_text(root_node.text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Original index and saving it at: /workspaces/sec-insights/backend/eval/index_storage/original\n",
      "Creating Sentence-Window index and saving it at: /workspaces/sec-insights/backend/eval/index_storage/setence_window\n",
      "Creating Auto-Merging index and saving it at: /workspaces/sec-insights/backend/eval/index_storage/auto_merging\n"
     ]
    }
   ],
   "source": [
    "# build indexes\n",
    "import os\n",
    "from llama_index.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "ORIGINAL_PERSIST_DIR = '/workspaces/sec-insights/backend/eval/index_storage/original'   # local dir to persist storage of index\n",
    "if not os.path.exists(ORIGINAL_PERSIST_DIR):                                            # check if storage already exists\n",
    "    print(f\"Creating Original index and saving it at: {ORIGINAL_PERSIST_DIR}\")\n",
    "    original_index = VectorStoreIndex(original_nodes)                                   # create the index\n",
    "    original_index.storage_context.persist(persist_dir=ORIGINAL_PERSIST_DIR)            # store it for later\n",
    "else:\n",
    "    print(f\"Original index exists - loading it from: {ORIGINAL_PERSIST_DIR}\")\n",
    "    original_storage_context = StorageContext.from_defaults(persist_dir=ORIGINAL_PERSIST_DIR)   # load the existing index\n",
    "    original_index = load_index_from_storage(original_storage_context)\n",
    "\n",
    "SENTENCE_WINDOW_PERSIST_DIR = '/workspaces/sec-insights/backend/eval/index_storage/setence_window'\n",
    "if not os.path.exists(SENTENCE_WINDOW_PERSIST_DIR):\n",
    "    print(f\"Creating Sentence-Window index and saving it at: {SENTENCE_WINDOW_PERSIST_DIR}\")\n",
    "    sentence_window_index = VectorStoreIndex.from_documents(\n",
    "        document,\n",
    "        service_context=sentence_window_service_context,\n",
    "    )\n",
    "    sentence_window_index.storage_context.persist(persist_dir=SENTENCE_WINDOW_PERSIST_DIR)\n",
    "else:\n",
    "    print(f\"Sentence-Window index exists - loading it from: {SENTENCE_WINDOW_PERSIST_DIR}\")\n",
    "    setence_window_storage_context = StorageContext.from_defaults(persist_dir=SENTENCE_WINDOW_PERSIST_DIR)\n",
    "    sentence_window_index = load_index_from_storage(\n",
    "        storage_context=setence_window_storage_context,\n",
    "        service_context=sentence_window_service_context,\n",
    "    )\n",
    "\n",
    "AUTO_MERGING_PERSIST_DIR = '/workspaces/sec-insights/backend/eval/index_storage/auto_merging'\n",
    "auto_merging_storage_context = StorageContext.from_defaults()\n",
    "auto_merging_storage_context.docstore.add_documents(hierarchical_nodes)\n",
    "if not os.path.exists(AUTO_MERGING_PERSIST_DIR):\n",
    "    print(f\"Creating Auto-Merging index and saving it at: {AUTO_MERGING_PERSIST_DIR}\")\n",
    "    auto_merging_index = VectorStoreIndex(\n",
    "        leaf_nodes,\n",
    "        storage_context=auto_merging_storage_context,\n",
    "        service_context=auto_merging_service_context\n",
    "    )\n",
    "    auto_merging_index.storage_context.persist(AUTO_MERGING_PERSIST_DIR)\n",
    "else:\n",
    "    print(f\"Auto-Merging index exists - loading it from: {AUTO_MERGING_PERSIST_DIR}\")\n",
    "    auto_merging_index = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=AUTO_MERGING_PERSIST_DIR),\n",
    "        service_context=auto_merging_service_context\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build original query engine\n",
    "original_query_engine = original_index.as_query_engine(\n",
    "    similarity_top_k=3                                      # same as original source code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sentence-window query engine\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor, LLMRerank\n",
    "postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "sentence_window_rerank = LLMRerank(\n",
    "    top_n=3,\n",
    "    service_context=sentence_window_service_context,\n",
    ")\n",
    "sentence_window_query_engine = sentence_window_index.as_query_engine(\n",
    "    similarity_top_k=6, node_postprocessors=[postproc, sentence_window_rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build auto-merging query engine\n",
    "from llama_index.retrievers import AutoMergingRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "base_retriever = auto_merging_index.as_retriever(\n",
    "    similarity_top_k=12,    # number of nodes that must be retrieved to merge into parent\n",
    ")\n",
    "auto_merging_retriever = AutoMergingRetriever(\n",
    "    base_retriever, auto_merging_storage_context,\n",
    ")\n",
    "auto_merging_rerank = LLMRerank(\n",
    "    top_n=2,\n",
    "    service_context=auto_merging_service_context,\n",
    ")\n",
    "auto_merging_query_engine = RetrieverQueryEngine.from_args(\n",
    "    auto_merging_retriever, node_postprocessors=[auto_merging_rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare The Responses of each Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is Meta's mission?\n",
      "Excerpt from META 2022 10-K Document: Our mission is to give people the power to build community and bring the world closer together.\n",
      "\n",
      "ORIGINAL QUERY ENGINE RESPONSE:\n",
      "Meta's mission is to provide a holistic approach to benefits through Life@Meta, offering a wide range of resources to help employees and their dependents thrive. Additionally, Meta aims to invest in employee learning and development, conduct regular surveys to understand employee sentiment, and design health and well-being programs to support employees in reaching their personal well-being goals.\n",
      "\n",
      "SENTENCE-WINDOW QUERY ENGINE RESPONSE:\n",
      "Meta's mission is to give people the power to build community and bring the world closer together.\n",
      "\n",
      "AUTO-MERGING QUERY ENGINE RESPONSE:\n",
      "Meta's mission is to give people the power to build community and bring the world closer together.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is Meta's mission?\"\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Excerpt from META 2022 10-K Document: Our mission is to give people the power to build community and bring the world closer together.\")\n",
    "\n",
    "# Test Original response\n",
    "original_response = original_query_engine.query(prompt)\n",
    "sentence_window_response = sentence_window_query_engine.query(prompt)\n",
    "auto_merging_response = auto_merging_query_engine.query(prompt)\n",
    "\n",
    "print(f\"\\nORIGINAL QUERY ENGINE RESPONSE:\\n{str(original_response)}\")\n",
    "print(f\"\\nSENTENCE-WINDOW QUERY ENGINE RESPONSE:\\n{str(sentence_window_response)}\")\n",
    "print(f\"\\nAUTO-MERGING QUERY ENGINE RESPONSE:\\n{str(auto_merging_response)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset already exists at: /workspaces/sec-insights/backend/eval/eval_dataset.json\n"
     ]
    }
   ],
   "source": [
    "# generate a dataset to be used for evaluation\n",
    "from eval import generate_dataset\n",
    "from llama_index.node_parser import SentenceSplitter\n",
    "from llama_index.evaluation import DatasetGenerator, QueryResponseDataset\n",
    "import random\n",
    "\n",
    "file_path=\"/workspaces/sec-insights/backend/eval/eval_dataset.json\"     # path to save evaluation dataset\n",
    "if not os.path.exists(file_path):\n",
    "    text_splitter = SentenceSplitter()\n",
    "    base_nodes = text_splitter.get_nodes_from_documents(document)\n",
    "\n",
    "    # Use the middle 80% of document context to generate questions in evaluation dataset\n",
    "    start_index = int(len(base_nodes) * 0.1)\n",
    "    end_index = int(len(base_nodes) * 0.9)\n",
    "\n",
    "    num_nodes_eval = 20     #  The number of nodes (randomly sampled from total nodes) to use for generating evaluation questions.\n",
    "    sample_eval_nodes = random.sample(base_nodes[start_index:end_index], num_nodes_eval)\n",
    "\n",
    "    from llama_index.evaluation import DatasetGenerator\n",
    "    dataset_generator = DatasetGenerator(\n",
    "        nodes=sample_eval_nodes,\n",
    "        # llm=OpenAI(model=\"gpt-4\"),\n",
    "        service_context=original_service_context,       # experiment using other service contexts (i.e., sentence-window, auto-merging)\n",
    "        num_questions_per_chunk=2,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    eval_dataset = await dataset_generator.agenerate_dataset_from_nodes()\n",
    "    eval_dataset.save_json(file_path)\n",
    "    print(f\"Saved evaluation dataset at: {file_path}\")\n",
    "else: \n",
    "    print(f\"Evaluation dataset already exists at: {file_path}\")\n",
    "    eval_dataset = QueryResponseDataset.from_json(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Query Engines on Following Metrics:\n",
    "- Correctness: The correctness of a response - A score between 1 (worst) and 5 (best).\n",
    "- Semantic Similarity: The similarity between embeddings of the generated answer and reference answer.\n",
    "- Relevance: The relevance of retrieved context and response to the query. Considers the query string, retrieved context, and response string.\n",
    "- Faithfulness: How well the response is supported by the retrieved context (i.e., Is there hallucination?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_='''\n",
    "Note - The following code snippet had to be added to the CorrectnessEvaluator class within the llama-index v\"0.9.7\" package at\n",
    "llama_index/evaluation/correctness.py before line: score_str, reasoning_str = eval_response.split(\"\\n\", 1)\n",
    "This resolves an issue where eval_resonse is created beginning with a newline character, resulting in an error trying to convert\n",
    "an empty str to a float on line: score = float(score_str).\n",
    "\n",
    "Code snippet:\n",
    "if eval_response[0] == '\\n':\n",
    "    eval_response = eval_response[1:]\n",
    "'''\n",
    "# import llama_index.evaluation\n",
    "# from importlib import reload\n",
    "# reload(llama_index.evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import CorrectnessEvaluator, SemanticSimilarityEvaluator, RelevancyEvaluator, FaithfulnessEvaluator, BatchEvalRunner\n",
    "from llama_index.evaluation.eval_utils import get_responses\n",
    "\n",
    "evaluator_c = CorrectnessEvaluator()\n",
    "evaluator_s = SemanticSimilarityEvaluator()\n",
    "evaluator_r = RelevancyEvaluator()\n",
    "evaluator_f = FaithfulnessEvaluator()\n",
    "\n",
    "evaluator_dict = {\n",
    "    \"correctness\": evaluator_c,\n",
    "    \"faithfulness\": evaluator_f,\n",
    "    \"relevancy\": evaluator_r,\n",
    "    \"semantic_similarity\": evaluator_s,\n",
    "}\n",
    "batch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)\n",
    "\n",
    "eval_qs = eval_dataset.questions\n",
    "ref_response_strs = [r for (_, r) in eval_dataset.qr_pairs]\n",
    "\n",
    "max_samples = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.03it/s]\n"
     ]
    }
   ],
   "source": [
    "original_pred_responses = get_responses(\n",
    "    eval_qs[:max_samples], original_query_engine, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence_window_pred_responses = get_responses(\n",
    "    eval_qs[:max_samples], sentence_window_query_engine, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:40<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "auto_merging_pred_responses = get_responses(\n",
    "    eval_qs[:max_samples], auto_merging_query_engine, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:34<00:00,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "original_eval_results = await batch_runner.aevaluate_responses(\n",
    "    queries=eval_qs[:max_samples],\n",
    "    responses=original_pred_responses[:max_samples],\n",
    "    reference=ref_response_strs[:max_samples],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:34<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_window_eval_results = await batch_runner.aevaluate_responses(\n",
    "    queries=eval_qs[:max_samples],\n",
    "    responses=sentence_window_pred_responses[:max_samples],\n",
    "    reference=ref_response_strs[:max_samples],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:40<00:00,  1.99it/s]\n"
     ]
    }
   ],
   "source": [
    "auto_merging_eval_results = await batch_runner.aevaluate_responses(\n",
    "    queries=eval_qs[:max_samples],\n",
    "    responses=auto_merging_pred_responses[:max_samples],\n",
    "    reference=ref_response_strs[:max_samples],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation.eval_utils import get_results_df\n",
    "results_df = get_results_df(\n",
    "    [original_eval_results, sentence_window_eval_results, auto_merging_eval_results],\n",
    "    [\"Base Retriever\", \"Sentence-Window Retriever\", \"Auto-Merging Retriever\"],\n",
    "    [\"correctness\", \"relevancy\", \"faithfulness\", \"semantic_similarity\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>correctness</th>\n",
       "      <th>relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>4.250</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.963678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence-Window Retriever</td>\n",
       "      <td>4.225</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto-Merging Retriever</td>\n",
       "      <td>4.075</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       names  correctness  relevancy  faithfulness  \\\n",
       "0             Base Retriever        4.250       0.90           1.0   \n",
       "1  Sentence-Window Retriever        4.225       0.95           1.0   \n",
       "2     Auto-Merging Retriever        4.075       0.95           1.0   \n",
       "\n",
       "   semantic_similarity  \n",
       "0             0.963678  \n",
       "1             0.973731  \n",
       "2             0.966431  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to CSV file\n",
    "OUTPUT_PATH = '/workspaces/sec-insights/backend/eval/results.csv'\n",
    "results_df.to_csv(OUTPUT_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
