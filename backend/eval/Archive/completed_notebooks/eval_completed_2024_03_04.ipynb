{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document already exists at: /workspaces/sec-insights/backend/eval/document_storage/META_SEC_10-K_2022.json\n"
     ]
    }
   ],
   "source": [
    "# Check if document exists. If not, get it and save it.\n",
    "import os\n",
    "import requests\n",
    "from app import schema\n",
    "from app.chat.engine import fetch_and_read_document\n",
    "from llama_index.storage.docstore import SimpleDocumentStore\n",
    "\n",
    "DOCUMENT_PERSIST_PATH = '/workspaces/sec-insights/backend/eval/document_storage/META_SEC_10-K_2022.json'\n",
    "if not os.path.exists(DOCUMENT_PERSIST_PATH):\n",
    "\n",
    "    # Get document from secinsights.ai production API\n",
    "    base_url = \"https://llama-app-backend.onrender.com\"     # Production backend base URL\n",
    "    prod_document_id = \"922f4a9f-7bc9-4fb1-b9b8-fa5a84c1cbcc\"    # META 10-K 2022\n",
    "\n",
    "    response = requests.get(f\"{base_url}/api/document/{prod_document_id}\")\n",
    "    data = response.json()\n",
    "    document = schema.Document(**data)\n",
    "    document = fetch_and_read_document(document)     # merge document pages into a single document\n",
    "\n",
    "    document_docstore = SimpleDocumentStore()\n",
    "    document_docstore.add_documents(document)\n",
    "    document_docstore.persist(DOCUMENT_PERSIST_PATH)\n",
    "    print(f\"Saved document at: {DOCUMENT_PERSIST_PATH}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Document already exists at: {DOCUMENT_PERSIST_PATH}\")\n",
    "    document_docstore = SimpleDocumentStore().from_persist_path(DOCUMENT_PERSIST_PATH)\n",
    "\n",
    "# Get ID of document in docstore\n",
    "docs = document_docstore.docs\n",
    "keys_list = list(docs.keys())\n",
    "doc_id = list(docs.keys())[0]       # Meta document is only document in docstore -- so, first key must be it's ID\n",
    "\n",
    "meta_doc = document_docstore.get_document(doc_id=doc_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633d282d-f822-4097-a8f6-a8ed533bc6d7\n"
     ]
    }
   ],
   "source": [
    "type(meta_doc)\n",
    "print(meta_doc.id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anyio\n",
    "from app.chat.messaging import ChatCallbackHandler\n",
    "\n",
    "send_chan, recv_chan = anyio.create_memory_object_stream(100)\n",
    "callback_handler = ChatCallbackHandler(send_chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### CREATING SERVICE CONTEXT USING original NODE PARSER #########################\n",
      "Original node parsing exists - loading it from: /workspaces/sec-insights/backend/eval/node_storage/original_nodes.json\n"
     ]
    }
   ],
   "source": [
    "# get original node parsing\n",
    "import os\n",
    "from llama_index.storage.docstore import SimpleDocumentStore\n",
    "from app.chat.engine import get_tool_service_context\n",
    "\n",
    "ORIGINAL_NODES_PERSIST_PATH = '/workspaces/sec-insights/backend/eval/node_storage/original_nodes.json'\n",
    "\n",
    "original_service_context = get_tool_service_context(callback_handlers=[callback_handler], node_parser_type=\"original\")\n",
    "original_node_parser = original_service_context.node_parser\n",
    "\n",
    "if not os.path.exists(ORIGINAL_NODES_PERSIST_PATH):\n",
    "    print(f\"Creating original node parsing and saving at: {ORIGINAL_NODES_PERSIST_PATH}\")\n",
    "    original_nodes = original_node_parser.get_nodes_from_documents([meta_doc])\n",
    "    original_docstore = SimpleDocumentStore()\n",
    "    original_docstore.add_documents(original_nodes)\n",
    "    original_docstore.persist(ORIGINAL_NODES_PERSIST_PATH)\n",
    "else:\n",
    "    print(f\"Original node parsing exists - loading it from: {ORIGINAL_NODES_PERSIST_PATH}\")\n",
    "    original_docstore = SimpleDocumentStore().from_persist_path(ORIGINAL_NODES_PERSIST_PATH)\n",
    "    original_document = original_docstore.docs\n",
    "    original_nodes = list(original_document.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 327\n",
      "\n",
      "################################################## ORIGINAL NODE ##################################################\n",
      "We have based these forward-looking statements largely on our current expectations and projections about future events and trends that we believe may affect our financial condition, results of operations, business strategy, short-term and long-term business operations and objectives, and financial needs. These forward-looking statements are subject to a number of risks, uncertainties and assumptions, including those described in Part I, Item 1A, \"Risk Factors\" in this Annual Report on Form 10-K. Moreover, we operate in a very competitive and rapidly changing environment. New risks emerge from time to time. It is not possible for our management to predict all risks, nor can we assess the impact of all factors on our business or the extent to which any factor, or combination of factors, may cause actual results to differ materially from those contained in any forward-looking statements we may make. In light of these risks, uncertainties and assumptions, the future events and trends discussed in this Annual Report on Form 10-K may not occur and actual results could differ materially and adversely from those anticipated or implied in the forward-looking statements. We undertake no obligation to revise or publicly release the results of any revision to these forward-looking statements, except as required by law. Given these risks and uncertainties, readers are cautioned not to place undue reliance on such forward-looking statements.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total nodes: {len(original_nodes)}\")\n",
    "\n",
    "from eval import format_pdf_text\n",
    "print(f\"\\n{'#'*50} ORIGINAL NODE {'#'*50}\\n{format_pdf_text(original_nodes[5].text)}\")\n",
    "\n",
    "## Additional Output\n",
    "# print(f\"\\ntype(original_nodes): {type(original_nodes)}\")\n",
    "# print(f\"type(original_nodes[0]): {type(original_nodes[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### CREATING SERVICE CONTEXT USING sentence-window NODE PARSER #########################\n",
      "Sentence window node parsing exists - loading it from: /workspaces/sec-insights/backend/eval/node_storage/sentence_window_nodes.json\n"
     ]
    }
   ],
   "source": [
    "# get sentence-window node parsing\n",
    "\n",
    "SENTENCE_WINDOW_NODES_PERSIST_PATH = '/workspaces/sec-insights/backend/eval/node_storage/sentence_window_nodes.json'\n",
    "\n",
    "sentence_window_service_context = get_tool_service_context(callback_handlers=[callback_handler], node_parser_type=\"sentence-window\")\n",
    "sentence_window_node_parser = sentence_window_service_context.node_parser\n",
    "\n",
    "if not os.path.exists(SENTENCE_WINDOW_NODES_PERSIST_PATH):\n",
    "    print(f\"Creating sentence window node parsing and saving at: {SENTENCE_WINDOW_NODES_PERSIST_PATH}\")\n",
    "    sentence_window_nodes = sentence_window_node_parser.get_nodes_from_documents([meta_doc])\n",
    "    sentence_window_docstore = SimpleDocumentStore()\n",
    "    sentence_window_docstore.add_documents(sentence_window_nodes)\n",
    "    sentence_window_docstore.persist(SENTENCE_WINDOW_NODES_PERSIST_PATH)\n",
    "\n",
    "else:\n",
    "    print(f\"Sentence window node parsing exists - loading it from: {SENTENCE_WINDOW_NODES_PERSIST_PATH}\")\n",
    "    sentence_window_docstore = SimpleDocumentStore().from_persist_path(SENTENCE_WINDOW_NODES_PERSIST_PATH)\n",
    "    sentence_window_document = sentence_window_docstore.docs\n",
    "    sentence_window_nodes = list(sentence_window_document.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentence-window nodes: 2184\n",
      "Window_size = 2\n",
      "\n",
      "Sentence-Window node:\n",
      "\n",
      "################################################## SENTENCE ##################################################\n",
      "Yes ☐ No ☒ Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 (Exchange Act) during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days.\n",
      "\n",
      "################################################## WINDOW ##################################################\n",
      "Employer Identification Number) 1601 Willow Road , Menlo Park , California 94025 (Address of principal executive offices and Zip Code) ( 650 ) 543-4800 (Registrant's telephone number, including area code) __________________________ Securities registered pursuant to Section 12(b) of the Act: Title of each class Trading symbol(s) Name of each exchange on which registered Class A Common Stock, $0.000006 par value META The Nasdaq Stock Market LLC Securities registered pursuant to Section 12(g) of the Act: None Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes ☒ No ☐ Indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act. Yes ☐ No ☒ Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 (Exchange Act) during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes ☒ No ☐ Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (§ 232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files).\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total sentence-window nodes: {len(sentence_window_nodes)}\")\n",
    "print(f\"Window_size = {sentence_window_node_parser.window_size}\")\n",
    "\n",
    "sentence = format_pdf_text(sentence_window_nodes[5].metadata.get(\"original_text\"))\n",
    "window = format_pdf_text(sentence_window_nodes[5].metadata.get(\"window\"))\n",
    "\n",
    "print(f\"\\nSentence-Window node:\")\n",
    "print(f\"\\n{'#'*50} SENTENCE {'#'*50}\\n{sentence}\")\n",
    "print(f\"\\n{'#'*50} WINDOW {'#'*50}\\n{window}\")\n",
    "\n",
    "# ## Additional Output\n",
    "# print(f\"\\ntype(sentence_window_nodes): {type(sentence_window_nodes)}\")\n",
    "# print(f\"type(sentence_window_nodes[0]): {type(sentence_window_nodes[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### CREATING SERVICE CONTEXT USING hierarchical NODE PARSER #########################\n",
      "Hierarchical node parsing exists - loading it from: /workspaces/sec-insights/backend/eval/node_storage/hierarchical_nodes.json\n"
     ]
    }
   ],
   "source": [
    "# get hierarchical node parsing\n",
    "HIERARCHICAL_NODES_PERSIST_PATH = '/workspaces/sec-insights/backend/eval/node_storage/hierarchical_nodes.json'\n",
    "\n",
    "auto_merging_service_context = get_tool_service_context(callback_handlers=[callback_handler], node_parser_type=\"hierarchical\")\n",
    "hierarchical_node_parser = auto_merging_service_context.node_parser\n",
    "\n",
    "if not os.path.exists(HIERARCHICAL_NODES_PERSIST_PATH):\n",
    "    print(f\"Creating hierarchical node parsing and saving at: {HIERARCHICAL_NODES_PERSIST_PATH}\")\n",
    "    hierarchical_nodes = hierarchical_node_parser.get_nodes_from_documents([meta_doc])\n",
    "    hierarchical_docstore = SimpleDocumentStore()\n",
    "    hierarchical_docstore.add_documents(hierarchical_nodes)\n",
    "    hierarchical_docstore.persist(HIERARCHICAL_NODES_PERSIST_PATH)\n",
    "\n",
    "else:\n",
    "    print(f\"Hierarchical node parsing exists - loading it from: {HIERARCHICAL_NODES_PERSIST_PATH}\")\n",
    "    hierarchical_docstore = SimpleDocumentStore().from_persist_path(HIERARCHICAL_NODES_PERSIST_PATH)\n",
    "    hierarchical_document = hierarchical_docstore.docs\n",
    "    hierarchical_nodes = list(hierarchical_document.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node hierarchy (chunk sizes): [2048, 512, 128]\n",
      "Total hierarchical nodes: 2556\n",
      "Total leaf nodes: 2119\n"
     ]
    }
   ],
   "source": [
    "from llama_index.node_parser import get_leaf_nodes\n",
    "leaf_nodes = get_leaf_nodes(hierarchical_nodes)\n",
    "\n",
    "print(f\"Node hierarchy (chunk sizes): {hierarchical_node_parser.chunk_sizes}\")\n",
    "print(f\"Total hierarchical nodes: {len(hierarchical_nodes)}\")\n",
    "print(f\"Total leaf nodes: {len(leaf_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice how each node is a subset of its parent:\n",
      "\n",
      "################################################## LEAF NODE ##################################################\n",
      "UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C.\n",
      "\n",
      "################################################## INTERMEDIATE NODE ##################################################\n",
      "UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549 __________________________ FORM 10-K __________________________ (Mark One) ☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the fiscal year ended December 31 , 2022 or ☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 For the transition period from to Commission File Number: 001-35551 __________________________ Meta Platforms, Inc. (Exact name of registrant as specified in its charter) __________________________ Delaware 20-1665019 (State or other jurisdiction of incorporation or organization) (I.R.S. Employer Identification Number) 1601 Willow Road , Menlo Park , California 94025 (Address of principal executive offices and Zip Code) ( 650 ) 543-4800 (Registrant's telephone number, including area code) __________________________ Securities registered pursuant to Section 12(b) of the Act: Title of each class Trading symbol(s) Name of each exchange on which registered Class A Common Stock, $0.000006 par value META The Nasdaq Stock Market LLC Securities registered pursuant to Section 12(g) of the Act: None Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.\n"
     ]
    }
   ],
   "source": [
    "# function to get parent of a hierarchical node\n",
    "get_parent_node = lambda node, all_nodes: next(i for i in all_nodes if i.id_ == node.parent_node.node_id)\n",
    "\n",
    "# get intermediate & root nodes\n",
    "leaf_node = leaf_nodes[0]\n",
    "intermediate_node = get_parent_node(leaf_node, hierarchical_nodes)\n",
    "root_node = get_parent_node(intermediate_node, hierarchical_nodes)\n",
    "\n",
    "print(f\"Notice how each node is a subset of its parent:\")\n",
    "print(f\"\\n{'#'*50} LEAF NODE {'#'*50}\\n{format_pdf_text(leaf_node.text)}\")\n",
    "print(f\"\\n{'#'*50} INTERMEDIATE NODE {'#'*50}\\n{format_pdf_text(intermediate_node.text)}\")\n",
    "# print(f\"\\n{'#'*50} ROOT NODE {'#'*50}\\n{format_pdf_text(root_node.text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original index exists - loading it from: /workspaces/sec-insights/backend/eval/index_storage/original\n",
      "Sentence-Window index exists - loading it from: /workspaces/sec-insights/backend/eval/index_storage/setence_window\n",
      "Auto-Merging index exists - loading it from: /workspaces/sec-insights/backend/eval/index_storage/auto_merging_2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "ORIGINAL_PERSIST_DIR = '/workspaces/sec-insights/backend/eval/index_storage/original'   # local dir to persist storage of index\n",
    "if not os.path.exists(ORIGINAL_PERSIST_DIR):                                            # check if storage already exists\n",
    "    print(f\"Creating Original index and saving it at: {ORIGINAL_PERSIST_DIR}\")\n",
    "    original_index = VectorStoreIndex(original_nodes)                                   # create the index\n",
    "    original_index.storage_context.persist(persist_dir=ORIGINAL_PERSIST_DIR)            # store it for later\n",
    "else:\n",
    "    print(f\"Original index exists - loading it from: {ORIGINAL_PERSIST_DIR}\")\n",
    "    original_storage_context = StorageContext.from_defaults(persist_dir=ORIGINAL_PERSIST_DIR)   # load the existing index\n",
    "    original_index = load_index_from_storage(original_storage_context)\n",
    "\n",
    "SENTENCE_WINDOW_PERSIST_DIR = '/workspaces/sec-insights/backend/eval/index_storage/setence_window'\n",
    "if not os.path.exists(SENTENCE_WINDOW_PERSIST_DIR):\n",
    "    print(f\"Creating Sentence-Window index and saving it at: {SENTENCE_WINDOW_PERSIST_DIR}\")\n",
    "    sentence_window_index = VectorStoreIndex.from_documents(\n",
    "        [meta_doc],\n",
    "        service_context=sentence_window_service_context,\n",
    "    )\n",
    "    sentence_window_index.storage_context.persist(persist_dir=SENTENCE_WINDOW_PERSIST_DIR)\n",
    "else:\n",
    "    print(f\"Sentence-Window index exists - loading it from: {SENTENCE_WINDOW_PERSIST_DIR}\")\n",
    "    setence_window_storage_context = StorageContext.from_defaults(persist_dir=SENTENCE_WINDOW_PERSIST_DIR)\n",
    "    sentence_window_index = load_index_from_storage(\n",
    "        storage_context=setence_window_storage_context,\n",
    "        service_context=sentence_window_service_context,\n",
    "    )\n",
    "\n",
    "AUTO_MERGING_INDEX_PERSIST_DIR = '/workspaces/sec-insights/backend/eval/index_storage/auto_merging_2'\n",
    "if not os.path.exists(AUTO_MERGING_INDEX_PERSIST_DIR):\n",
    "    print(f\"Creating Auto-Merging storage context and saving it at: {AUTO_MERGING_INDEX_PERSIST_DIR}\")\n",
    "    auto_merging_storage_context = StorageContext.from_defaults(\n",
    "        docstore=hierarchical_docstore,\n",
    "    )\n",
    "    auto_merging_index = VectorStoreIndex(\n",
    "        leaf_nodes,\n",
    "        storage_context=auto_merging_storage_context,\n",
    "        service_context=auto_merging_service_context\n",
    "    )\n",
    "    auto_merging_index.storage_context.persist(AUTO_MERGING_INDEX_PERSIST_DIR)\n",
    "else:\n",
    "    print(f\"Auto-Merging index exists - loading it from: {AUTO_MERGING_INDEX_PERSIST_DIR}\")\n",
    "    auto_merging_index = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=AUTO_MERGING_INDEX_PERSIST_DIR),\n",
    "        service_context=auto_merging_service_context\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Query Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build original query engine\n",
    "original_query_engine = original_index.as_query_engine(\n",
    "    similarity_top_k=3                                      # same as original source code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sentence-window query engine\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor, LLMRerank\n",
    "postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "sentence_window_rerank = LLMRerank(\n",
    "    top_n=2,\n",
    "    service_context=sentence_window_service_context,\n",
    ")\n",
    "sentence_window_query_engine = sentence_window_index.as_query_engine(\n",
    "    similarity_top_k=4, node_postprocessors=[postproc, sentence_window_rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build auto-merging query engine\n",
    "from llama_index.retrievers import AutoMergingRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "base_retriever = auto_merging_index.as_retriever(\n",
    "    similarity_top_k=12,\n",
    ")\n",
    "auto_merging_retriever = AutoMergingRetriever(\n",
    "    base_retriever, StorageContext.from_defaults(persist_dir=AUTO_MERGING_INDEX_PERSIST_DIR),   # base retriever and auto-merging storage context\n",
    ")\n",
    "auto_merging_rerank = LLMRerank(\n",
    "    top_n=4,\n",
    "    service_context=auto_merging_service_context,\n",
    ")\n",
    "auto_merging_query_engine = RetrieverQueryEngine.from_args(\n",
    "    auto_merging_retriever, node_postprocessors=[auto_merging_rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare The Responses of each Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is Meta's mission?\n",
      "Excerpt from META 2022 10-K Document: Our mission is to give people the power to build community and bring the world closer together.\n",
      "\n",
      "ORIGINAL QUERY ENGINE RESPONSE:\n",
      "Meta's mission is to move their offerings beyond 2D screens towards immersive experiences like augmented and virtual reality to help build the metaverse, which they believe is the next evolution in social technology. Their vision for the metaverse involves creating an entire ecosystem of experiences, devices, and new technologies, aiming for it to become the next computing platform and the future of social interaction.\n",
      "\n",
      "SENTENCE-WINDOW QUERY ENGINE RESPONSE:\n",
      "Meta's mission is to give people the power to build community and bring the world closer together.\n",
      "\n",
      "AUTO-MERGING QUERY ENGINE RESPONSE:\n",
      "Meta's mission is to give people the power to build community and bring the world closer together.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is Meta's mission?\"\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Excerpt from META 2022 10-K Document: Our mission is to give people the power to build community and bring the world closer together.\")\n",
    "\n",
    "original_response = original_query_engine.query(prompt)\n",
    "sentence_window_response = sentence_window_query_engine.query(prompt)\n",
    "auto_merging_response = auto_merging_query_engine.query(prompt)\n",
    "\n",
    "print(f\"\\nORIGINAL QUERY ENGINE RESPONSE:\\n{str(original_response)}\")\n",
    "print(f\"\\nSENTENCE-WINDOW QUERY ENGINE RESPONSE:\\n{str(sentence_window_response)}\")\n",
    "print(f\"\\nAUTO-MERGING QUERY ENGINE RESPONSE:\\n{str(auto_merging_response)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()    # allow asynchonous code to run within Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset already exists at: /workspaces/sec-insights/backend/eval/eval_dataset.json\n"
     ]
    }
   ],
   "source": [
    "from eval import generate_dataset\n",
    "from llama_index.node_parser import SentenceSplitter\n",
    "from llama_index.evaluation import DatasetGenerator, QueryResponseDataset\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index import ServiceContext\n",
    "import random\n",
    "\n",
    "file_path=\"/workspaces/sec-insights/backend/eval/eval_dataset.json\"     # path to save evaluation dataset\n",
    "if not os.path.exists(file_path):\n",
    "    text_splitter = SentenceSplitter()\n",
    "    base_nodes = text_splitter.get_nodes_from_documents(document)\n",
    "\n",
    "    # Use the middle 80% of document context to generate questions in evaluation dataset\n",
    "    start_index = int(len(base_nodes) * 0.1)\n",
    "    end_index = int(len(base_nodes) * 0.9)\n",
    "\n",
    "    num_nodes_eval = 30    #  The number of nodes (randomly sampled from total nodes) to use for generating evaluation questions.\n",
    "    sample_eval_nodes = random.sample(base_nodes[start_index:end_index], num_nodes_eval)\n",
    "\n",
    "    dataset_generator_llm = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "    dataset_generator_service_context = ServiceContext.from_defaults(llm=dataset_generator_llm)\n",
    "    \n",
    "    dataset_generator = DatasetGenerator(\n",
    "        nodes=sample_eval_nodes,\n",
    "        service_context=original_service_context,\n",
    "        # service_context=dataset_generator_service_context,        # rate limiting issues using gpt-4\n",
    "        num_questions_per_chunk=2,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    eval_dataset = await dataset_generator.agenerate_dataset_from_nodes()\n",
    "    eval_dataset.save_json(file_path)\n",
    "    print(f\"Saved evaluation dataset at: {file_path}\")\n",
    "\n",
    "else: \n",
    "    print(f\"Evaluation dataset already exists at: {file_path}\")\n",
    "    eval_dataset = QueryResponseDataset.from_json(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Query Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_='''\n",
    "Note - The following code snippet had to be added to the CorrectnessEvaluator class within the llama-index v\"0.9.7\" package at\n",
    "llama_index/evaluation/correctness.py before line: score_str, reasoning_str = eval_response.split(\"\\n\", 1)\n",
    "This resolves an issue where eval_resonse is created beginning with a newline character, resulting in an error trying to convert\n",
    "an empty str to a float on line: score = float(score_str).\n",
    "\n",
    "Code snippet:\n",
    "if eval_response[0] == '\\n':\n",
    "    eval_response = eval_response[1:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 questions in dataset\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Evaluate responses based on the following metrics:\n",
    "    Correctness:            The correctness of a response - A score between 1 (worst) and 5 (best).\n",
    "    Semantic Similarity:    The similarity between embeddings of the generated answer and reference answer.\n",
    "    Relevance:              The relevance of retrieved context and response to the query. Considers the query string, retrieved context, and response string.\n",
    "    Faithfulness:           How well the response is supported by the retrieved context (i.e., Is there hallucination?)\n",
    "'''\n",
    "from llama_index.evaluation import CorrectnessEvaluator, SemanticSimilarityEvaluator, RelevancyEvaluator, FaithfulnessEvaluator, BatchEvalRunner\n",
    "from llama_index.evaluation.eval_utils import get_responses\n",
    "\n",
    "evaluator_c = CorrectnessEvaluator()\n",
    "evaluator_s = SemanticSimilarityEvaluator()\n",
    "evaluator_r = RelevancyEvaluator()\n",
    "evaluator_f = FaithfulnessEvaluator()\n",
    "\n",
    "evaluator_dict = {\n",
    "    \"correctness\": evaluator_c,\n",
    "    \"faithfulness\": evaluator_f,\n",
    "    \"relevancy\": evaluator_r,\n",
    "    \"semantic_similarity\": evaluator_s,\n",
    "}\n",
    "batch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)\n",
    "\n",
    "eval_qs = eval_dataset.questions\n",
    "ref_response_strs = [r for (_, r) in eval_dataset.qr_pairs]\n",
    "print(f\"{len(eval_qs)} questions in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Responses from Each Query Engine for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 20\n",
    "\n",
    "import time\n",
    "time.sleep(12)\n",
    "print(f\"Original Query Engine\")\n",
    "original_pred_responses = get_responses(\n",
    "    eval_qs[:max_samples], original_query_engine, show_progress=True\n",
    ")\n",
    "time.sleep(12)\n",
    "print(f\"Sentence-Window Query Engine\")\n",
    "sentence_window_pred_responses = get_responses(\n",
    "    eval_qs[:max_samples], sentence_window_query_engine, show_progress=True\n",
    ")\n",
    "time.sleep(12)\n",
    "print(f\"Auto-Merging Query Engine\")\n",
    "auto_merging_pred_responses = get_responses(\n",
    "    eval_qs[:max_samples], auto_merging_query_engine, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 20\n",
    "queries = list(eval_dataset.queries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query Engine\n",
      "Making prediction 20/20\r"
     ]
    }
   ],
   "source": [
    "print(f\"Original Query Engine\")\n",
    "i = 0\n",
    "original_pred_responses = []\n",
    "while i < max_samples:\n",
    "    try:\n",
    "        print(f\"Making prediction {i + 1}/{max_samples}\", end='\\r', flush=True)\n",
    "        prompt = queries[i]\n",
    "        response = original_query_engine.query(prompt)\n",
    "        original_pred_responses.append(response)\n",
    "        i +=1\n",
    "    except Exception as e:\n",
    "        # Catch-all to handle exceptions\n",
    "        print(f\"Exception occured: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_pred_responses = get_responses(\n",
    "#     eval_qs[:max_samples], original_query_engine, show_progress=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-Window Query Engine\n",
      "Making prediction 20/20\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import RateLimitError\n",
    "print(f\"Sentence-Window Query Engine\")\n",
    "i = 0\n",
    "sentence_window_pred_responses = []\n",
    "while i < max_samples:\n",
    "    try:\n",
    "        print(f\"Making prediction {i + 1}/{max_samples}\", end='\\r', flush=True)\n",
    "        prompt = queries[i]\n",
    "        response = sentence_window_query_engine.query(prompt)\n",
    "        sentence_window_pred_responses.append(response)\n",
    "        i +=1\n",
    "        \n",
    "    except RateLimitError as rate_limit_err:\n",
    "        print(rate_limit_err)\n",
    "        sleep = 12\n",
    "        for s in range(sleep):\n",
    "            print(f\"waiting {s}/{sleep}s\", end='\\r', flush=True)\n",
    "            time.sleep(sleep)\n",
    "    except Exception as e:  # Catch-all to handle exceptions\n",
    "        print(f\"Exception occured: {e}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Sentence-Window Query Engine\")\n",
    "# sentence_window_pred_responses = get_responses(\n",
    "#     eval_qs[:max_samples], sentence_window_query_engine, show_progress=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making prediction 20/20\r"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "auto_merging_pred_responses = []\n",
    "while i <max_samples:\n",
    "    try:\n",
    "        print(f\"Making prediction {i + 1}/{max_samples}\", end='\\r', flush=True)\n",
    "        prompt = queries[i]\n",
    "        response = auto_merging_query_engine.query(prompt)\n",
    "        auto_merging_pred_responses.append(response)\n",
    "        i +=1\n",
    "\n",
    "    except RateLimitError as rate_limit_err:\n",
    "        print(rate_limit_err)\n",
    "        sleep = 12\n",
    "        for s in range(sleep):\n",
    "            print(f\"waiting {s}/{sleep}s\", end='\\r', flush=True)\n",
    "            time.sleep(1)\n",
    "    except Exception as e:  # Catch-all to handle exceptions\n",
    "        print(f\"Exception occured: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Auto-Merging Query Engine\")\n",
    "# auto_merging_pred_responses = get_responses(\n",
    "#     eval_qs[:max_samples], auto_merging_query_engine, show_progress=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Responses from Each Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query Engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:30<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "time.sleep(12)\n",
    "print(f\"Original Query Engine\")\n",
    "original_eval_results = await batch_runner.aevaluate_responses(\n",
    "    queries=eval_qs[:max_samples],\n",
    "    responses=original_pred_responses[:max_samples],\n",
    "    reference=ref_response_strs[:max_samples],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-Window Query Engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:29<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "time.sleep(12)\n",
    "print(f\"Sentence-Window Query Engine\")\n",
    "sentence_window_eval_results = await batch_runner.aevaluate_responses(\n",
    "    queries=eval_qs[:max_samples],\n",
    "    responses=sentence_window_pred_responses[:max_samples],\n",
    "    reference=ref_response_strs[:max_samples],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Merging Query Engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:28<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "time.sleep(12)\n",
    "print(f\"Auto-Merging Query Engine\")\n",
    "auto_merging_eval_results = await batch_runner.aevaluate_responses(\n",
    "    queries=eval_qs[:max_samples],\n",
    "    responses=auto_merging_pred_responses[:max_samples],\n",
    "    reference=ref_response_strs[:max_samples],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>correctness</th>\n",
       "      <th>relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.971983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence-Window Retriever</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto-Merging Retriever</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       names  correctness  relevancy  faithfulness  \\\n",
       "0             Base Retriever         4.20       0.95           0.9   \n",
       "1  Sentence-Window Retriever         4.20       1.00           1.0   \n",
       "2     Auto-Merging Retriever         4.05       0.95           1.0   \n",
       "\n",
       "   semantic_similarity  \n",
       "0             0.971983  \n",
       "1             0.971759  \n",
       "2             0.969437  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.evaluation.eval_utils import get_results_df\n",
    "results_df = get_results_df(\n",
    "    [original_eval_results, sentence_window_eval_results, auto_merging_eval_results],\n",
    "    [\"Base Retriever\", \"Sentence-Window Retriever\", \"Auto-Merging Retriever\"],\n",
    "    [\"correctness\", \"relevancy\", \"faithfulness\", \"semantic_similarity\"],\n",
    ")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to CSV file\n",
    "OUTPUT_PATH = '/workspaces/sec-insights/backend/eval/results/results_2024_03_04_samples-20.csv'\n",
    "results_df.to_csv(OUTPUT_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
